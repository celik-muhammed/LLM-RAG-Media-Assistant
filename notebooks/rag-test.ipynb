{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db448b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f35b1666-5393-458a-b747-177c1a1525ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f98df4-326c-4a0f-95a3-2441e1ced3ca",
   "metadata": {},
   "source": [
    "## Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "99950762",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Real IDs\n",
    "with open('../Data/documents-with-ids.json', 'rt') as f_in:\n",
    "    documents = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79e98356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(424,\n",
       " {'intent': 'report_copyright_infringement',\n",
       "  'question': 'can uhelp me submitting a notification of copyright  infringement',\n",
       "  'response': 'To address copyright infringement concerns, please adhere to the following guidelines:\\n\\n1. Access our website at {{WEBSITE_URL}}.\\n2. Go to the {{COPYRIGHT_SECTION}} area.\\n3. Find and select the {{REPORT_COPYRIGHT_INFRINGEMENT_OPTION}} choice.\\n4. Complete the necessary fields, providing comprehensive details regarding the infringement.\\n5. Submit the completed form for our assessment.\\n\\nYour submission will be reviewed, and we will take the requisite steps in line with our policies.',\n",
       "  'category': 'CONTENT',\n",
       "  'id': '1e254822'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents), documents[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a88433ad-dcc1-4455-a0df-3006b43c52a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1931, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generated questions\n",
    "df_question = pd.read_csv('../Data/ground-truth-data.csv')\n",
    "df_question.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6525af2-4c66-4f4a-88c2-91e0b6b8dc59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>category</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How do I go about reporting a copyright violat...</td>\n",
       "      <td>CONTENT</td>\n",
       "      <td>34b742ae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What steps are necessary to report an infringe...</td>\n",
       "      <td>CONTENT</td>\n",
       "      <td>34b742ae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Could you guide me through the process of fili...</td>\n",
       "      <td>CONTENT</td>\n",
       "      <td>34b742ae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When submitting evidence for potential piracy,...</td>\n",
       "      <td>CONTENT</td>\n",
       "      <td>34b742ae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What kind of responses can users expect after ...</td>\n",
       "      <td>CONTENT</td>\n",
       "      <td>34b742ae</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question category        id\n",
       "0  How do I go about reporting a copyright violat...  CONTENT  34b742ae\n",
       "1  What steps are necessary to report an infringe...  CONTENT  34b742ae\n",
       "2  Could you guide me through the process of fili...  CONTENT  34b742ae\n",
       "3  When submitting evidence for potential piracy,...  CONTENT  34b742ae\n",
       "4  What kind of responses can users expect after ...  CONTENT  34b742ae"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_question.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58472c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question    1\n",
       "category    0\n",
       "id          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_question.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "353c6e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>category</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>NaN</td>\n",
       "      <td>CONTENT</td>\n",
       "      <td>800255d0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    question category        id\n",
       "606      NaN  CONTENT  800255d0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_question[df_question.question.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c802861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1930, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_question = df_question.dropna()\n",
    "df_question.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e41a0aa-8f78-4aeb-b334-dd963d63a758",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = df_question.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c86b03ae-5a68-4ac4-9314-00b521b56272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How do I go about reporting a copyright violation on your platform?',\n",
       " 'category': 'CONTENT',\n",
       " 'id': '34b742ae'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f70bc03-575d-4576-8b1d-f82462feb485",
   "metadata": {},
   "source": [
    "## RAG flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1656629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['intent', 'question', 'response', 'category', 'id']),\n",
       " dict_keys(['question', 'category', 'id']))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].keys(), ground_truth[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "267f9429-4f31-4750-bdf4-84d0a3ec554a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.minsearch.Index at 0x163ad11cec0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import minsearch\n",
    "\n",
    "# Create a MinSearch index with specified text and keyword fields\n",
    "index = minsearch.Index(\n",
    "    text_fields=['intent', 'question', 'response'],  # full-text searchable fields\n",
    "    keyword_fields=['id', 'category'],  # fields for exact matching\n",
    ")\n",
    "\n",
    "# Fit the index to our document list\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d576457-2365-49bc-a573-df306e999c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_search(query):\n",
    "    boost = {}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query['question'],  # string directly or export\n",
    "        filter_dict={'category': query[\"category\"]},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9100bd80-431d-4990-98f7-0ef5ed0fd174",
   "metadata": {},
   "source": [
    "## Retrieval evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ad9e893-c880-4af5-b6df-4a9b2806d219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "# Compute Hit Rate: % of queries for which the correct document was retrieved\n",
    "def hit_rate(relevance_total):\n",
    "    cnt = 0\n",
    "    for line in relevance_total:\n",
    "        if True in line:  # If any retrieved doc matches the correct ID\n",
    "            cnt = cnt + 1\n",
    "    return cnt / len(relevance_total)\n",
    "\n",
    "\n",
    "# Compute Mean Reciprocal Rank (MRR)\n",
    "def mrr(relevance_total):\n",
    "    total_score = 0.0\n",
    "    for line in relevance_total:\n",
    "        for rank in range(len(line)):\n",
    "            if line[rank] == True:  # True means relevant doc found at this rank\n",
    "                total_score = total_score + 1 / (rank + 1)\n",
    "                # break  # only the first correct hit counts for MRR\n",
    "    return total_score / len(relevance_total)\n",
    "\n",
    "\n",
    "# Main evaluation loop\n",
    "def evaluate(ground_truth, search_function, disable=False):\n",
    "    relevance_total = []\n",
    "\n",
    "    for q in tqdm(ground_truth, disable=disable):  # iterate over each query\n",
    "        doc_id = q['id']  # correct document id\n",
    "        results = search_function(q)  # run search\n",
    "        relevance = [d['id'] == doc_id for d in results]  # check if results match the true id\n",
    "        relevance_total.append(relevance)  # collect all relevance flags\n",
    "\n",
    "    return {\n",
    "        'hit_rate': hit_rate(relevance_total),\n",
    "        'mrr': mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2dd4e92-ca43-4b0c-ae47-6ec89b83a622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4c36618b5374d23801cb9202dd15501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1930 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.04559585492227979, 'mrr': 0.015142898264659919}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate using the ground truth and the defined search function\n",
    "evaluate(ground_truth, lambda q: minsearch_search(q), disable=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfb38ee",
   "metadata": {},
   "source": [
    "# VectorSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c192ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install minsearch -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c855c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minsearch import VectorSearch  # For vector-based semantic search\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # TF-IDF text vectorization\n",
    "from sklearn.decomposition import TruncatedSVD  # Dimensionality reduction\n",
    "from sklearn.pipeline import make_pipeline  # To chain TF-IDF + SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b53306f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent': 'report_copyright_infringement',\n",
       " 'question': 'how can i report copyright violation',\n",
       " 'response': 'To report copyright infringement, please adhere to the following procedures:\\n\\n1. Access our website at {{WEBSITE_URL}}.\\n2. Direct yourself to the {{COPYRIGHT_SECTION}} section.\\n3. Find and click on the {{REPORT_COPYRIGHT_INFRINGEMENT_OPTION}} option.\\n4. Provide all required details regarding the infringement.\\n5. Submit the completed form for our assessment.\\n\\nUpon receiving your report, it will be carefully analyzed, and appropriate measures will be implemented in accordance with our guidelines.',\n",
       " 'category': 'CONTENT',\n",
       " 'id': '34b742ae'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa0e6dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c155d85fb1c64deea027a9f37dc01617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/424 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "texts = []\n",
    "\n",
    "for doc in tqdm(documents):\n",
    "    # Concatenate question and answer text\n",
    "    t = doc['question'] + ' ' + doc['response']\n",
    "    texts.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab2a0786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.61903956e-02, -3.32329444e-02,  1.84945311e-02, ...,\n",
       "        -4.48703441e-03,  4.45804900e-04, -1.82140197e-05],\n",
       "       [ 5.39078893e-02, -1.60753488e-03, -8.88495363e-02, ...,\n",
       "         1.12538530e-03, -2.76375777e-03,  7.13602034e-04],\n",
       "       [ 1.04216803e-01, -4.18585586e-02,  1.36393373e-02, ...,\n",
       "         4.17043648e-04,  1.47759318e-03,  9.44728636e-04],\n",
       "       ...,\n",
       "       [ 9.11410523e-02, -5.00482363e-02,  9.04754123e-03, ...,\n",
       "         4.46023998e-03,  4.19823652e-03, -6.38576361e-03],\n",
       "       [ 9.84283755e-02, -3.84751829e-02, -1.32054598e-02, ...,\n",
       "         9.42712159e-04, -3.55781865e-04, -3.01358641e-03],\n",
       "       [ 8.87460397e-02, -3.18344791e-02,  1.48513572e-02, ...,\n",
       "        -2.57281015e-03,  3.11055623e-03,  3.82499272e-03]],\n",
       "      shape=(424, 128))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a pipeline: TF-IDF vectorization + Truncated SVD (128 dimensions)\n",
    "pipeline = make_pipeline(\n",
    "    TfidfVectorizer(min_df=1, ngram_range=(1,1), norm='l1'),  # ignore rare words\n",
    "    TruncatedSVD(n_components=128, random_state=0)  # reduce to 128D\n",
    ")#.set_output(transform='pandas')\n",
    "\n",
    "# Fit and transform the texts into embeddings (2D numpy array)\n",
    "X = pipeline.fit_transform(texts)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "468a4405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.vector.VectorSearch at 0x1639cb9ede0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the vector index with 'id' as a keyword filter\n",
    "vindex = VectorSearch(keyword_fields=['category'])\n",
    "\n",
    "# Fit the vector index with our embeddings and original documents\n",
    "vindex.fit(X, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a83ea3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search_function(query):\n",
    "    # Convert the input question to a single embedding vector\n",
    "    query_vec = pipeline.transform([query[\"question\"]])  # shape: (1, 128) query is still only the question\n",
    "\n",
    "    # Run the vector search, filter by 'id'\n",
    "    return vindex.search(\n",
    "        query_vector=query_vec[0],  # use 1D vector\n",
    "        filter_dict={\"category\": query[\"category\"]},  # filter documents by id\n",
    "        num_results=5  # return top 5 matches\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "95b09dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac91b4bcdcc4180942ab6e4d838f798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1930 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.032642487046632127, 'mrr': 0.01636442141623488}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the same evaluation function from earlier\n",
    "results = evaluate(ground_truth, vector_search_function)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95137144-7060-4e4c-aba5-359de3085144",
   "metadata": {},
   "source": [
    "## Finding the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "387e641c-6592-4e4f-b191-1e5ca7598f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation = df_question[:len(df_question)//2]\n",
    "df_test = df_question[len(df_question)//2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a95c044-df61-4cb6-84a9-19ff9e1ef107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "def simple_optimize(param_ranges, objective_function, n_iterations=10):\n",
    "    best_params = None\n",
    "    best_score = float('-inf')  # Assuming we're minimizing. Use float('-inf') if maximizing.\n",
    "\n",
    "    for _ in range(n_iterations):\n",
    "        # Generate random parameters\n",
    "        current_params = {}\n",
    "        for param, (min_val, max_val) in param_ranges.items():\n",
    "            if isinstance(min_val, int) and isinstance(max_val, int):\n",
    "                current_params[param] = random.randint(min_val, max_val)\n",
    "            else:\n",
    "                current_params[param] = random.uniform(min_val, max_val)\n",
    "\n",
    "        # Evaluate the objective function\n",
    "        current_score = objective_function(current_params)\n",
    "\n",
    "        # Update best if current is better\n",
    "        if current_score > best_score:  # Change to > if maximizing\n",
    "            best_score = current_score\n",
    "            best_params = current_params\n",
    "\n",
    "    return best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6535225c-aa11-4875-895e-f84f2020083a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_val = df_validation.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33d2c962-b56a-4f1d-892a-1b84e89f4f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_search(query, boost=None):\n",
    "    if boost is None:\n",
    "        boost = {}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query['question'],  # string directly or export\n",
    "        filter_dict={'category': query[\"category\"]},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d61d688-45a0-40c9-bf5a-e87ad778ac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_ranges = {\n",
    "    'intent': (0.0, 10.0),\n",
    "    'question': (0.0, 10.0),\n",
    "    'response': (0.0, 10.0),\n",
    "    'category': (0.0, 10.0),\n",
    "}\n",
    "\n",
    "def objective(boost_params):\n",
    "    def search_function(q):\n",
    "        return minsearch_search(q, boost_params)\n",
    "\n",
    "    results = evaluate(gt_val, search_function)\n",
    "    return results['mrr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "85f903c6-9c07-4399-9cca-e12bda23e7b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68454182e55c4c7c911467b3683d31ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/965 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "764a031f0ec649b583ce145df4e31ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/965 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d52ec631f6548b79ef358a3e27792d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/965 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d366a60d328f43f0afa25932baabd9ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/965 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2677e4009e444961b57d7451f44b6972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/965 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cec85a96d0044ec8368e982328bfaed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/965 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1505380f774c4897a80bf59bac9391c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/965 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b139f26ce828472ca7c281a767e671e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/965 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c62c53fd8a614ae4b4a3d31737fbd7fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/965 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad33faf79499499897a8e5154cb62a95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/965 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae6592add2b44700bcc374476e7b7b93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/965 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef8dd6edd7344c65998222fc7525afeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/965 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52dbd7c1b414fe29882ef516ecda843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/965 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560507b79ef8447f8f10e08952482ef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/965 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f358194b1a4df4bd692801c398a370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/965 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b5b880e18e44b0fab330248186ef7a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/965 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05d9993e1d8e4e54b66edf3cd5cd8c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/965 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da51b20920a24d488ee189a5246e11f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/965 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82216074c24d4c5580af0c367ad92147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/965 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a199ccdf6ccf4b6f99a7705b46f562e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/965 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "({'intent': 1.1713429320851798,\n",
       "  'question': 2.204605368678285,\n",
       "  'response': 7.9458297171057595,\n",
       "  'category': 3.3253614921965546},\n",
       " 0.02115593387614112)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return best_params, best_score\n",
    "best_params, best_score = simple_optimize(param_ranges, objective, n_iterations=20)\n",
    "best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "50319af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-23 16:59:57,856] A new study created in memory with name: no-name-16bf3947-c49d-41e8-8b50-201fa591c352\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4af96bba3624783862ea300d58811d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-23 17:00:56,789] Trial 4 finished with value: 0.020615182169586306 and parameters: {'intent': 2.249132414867029, 'question': 2.234031749802022, 'response': 9.771698228947187, 'category': 1.9755464781730725}. Best is trial 4 with value: 0.020615182169586306.\n",
      "[I 2025-08-23 17:00:58,251] Trial 3 finished with value: 0.020734846615675623 and parameters: {'intent': 4.709344164326785, 'question': 0.9312117423908761, 'response': 5.71511647366386, 'category': 9.689631225548114}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:00:58,354] Trial 0 finished with value: 0.017276503001891597 and parameters: {'intent': 5.950954075284947, 'question': 0.09971871764905882, 'response': 8.47176229701623, 'category': 4.472868179991415}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:00:58,643] Trial 5 finished with value: 0.020581873509334644 and parameters: {'intent': 5.176019844107193, 'question': 1.329122027882893, 'response': 9.78720728619323, 'category': 7.318473055261165}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:01:00,529] Trial 6 finished with value: 0.015661238588699725 and parameters: {'intent': 1.5137686839708064, 'question': 9.722984383089203, 'response': 9.480673369531319, 'category': 9.412451545995546}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:01:01,042] Trial 7 finished with value: 0.013987581215560489 and parameters: {'intent': 1.9374334568133733, 'question': 8.270929875711662, 'response': 3.3709743142119963, 'category': 3.5734375764351336}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:01:01,293] Trial 1 finished with value: 0.017079940784603995 and parameters: {'intent': 7.911432025009639, 'question': 6.805885644660346, 'response': 9.352520978516337, 'category': 3.228507997770044}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:01:01,682] Trial 2 finished with value: 0.0138119911176906 and parameters: {'intent': 5.391854722063613, 'question': 9.750736988712061, 'response': 2.1277362059826785, 'category': 4.81779064435658}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:01:59,551] Trial 8 finished with value: 0.015613537297475118 and parameters: {'intent': 6.033461349887835, 'question': 7.470591877038064, 'response': 6.734065866929067, 'category': 2.060745743827068}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:02:01,437] Trial 11 finished with value: 0.013030676864873757 and parameters: {'intent': 5.768205192847679, 'question': 4.509489153435641, 'response': 0.13602763754374636, 'category': 7.9863637262241145}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:02:01,918] Trial 10 finished with value: 0.012958302491981249 and parameters: {'intent': 3.886850743541106, 'question': 4.445915257783348, 'response': 0.007153415847831468, 'category': 4.189156354293445}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:02:02,287] Trial 12 finished with value: 0.016130849576445425 and parameters: {'intent': 3.33974954285568, 'question': 5.088864544031458, 'response': 5.282349175363715, 'category': 5.7614703817933695}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:02:03,224] Trial 15 finished with value: 0.020166132083230526 and parameters: {'intent': 6.9853788347265535, 'question': 0.5262748155172414, 'response': 5.0913092621100065, 'category': 7.813155492263052}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:02:03,244] Trial 9 finished with value: 0.020619294349864287 and parameters: {'intent': 5.24376997497005, 'question': 0.684909922493635, 'response': 2.7028601013108435, 'category': 5.001423484884891}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:02:03,259] Trial 14 finished with value: 0.019824821120157904 and parameters: {'intent': 4.0014839492228935, 'question': 0.9389219168489926, 'response': 2.9860561132520456, 'category': 7.813368731823548}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:02:03,611] Trial 13 finished with value: 0.015255366395262765 and parameters: {'intent': 2.408253187637187, 'question': 8.101737952031293, 'response': 4.961078669379698, 'category': 6.229405312979902}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:03:02,734] Trial 16 finished with value: 0.01382926227485813 and parameters: {'intent': 9.728946854511113, 'question': 9.862846269869014, 'response': 3.634476366699384, 'category': 4.801226035756002}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:03:03,822] Trial 17 finished with value: 0.01806192943498643 and parameters: {'intent': 9.953760411131043, 'question': 3.843485048942842, 'response': 5.957583005019263, 'category': 0.15966346160665523}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:03:05,057] Trial 22 finished with value: 0.019414836746442957 and parameters: {'intent': 8.967216323298793, 'question': 2.7936106383325034, 'response': 7.496195830138598, 'category': 0.00939215804176019}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:03:05,590] Trial 18 finished with value: 0.019413191874331766 and parameters: {'intent': 2.7158501648319264, 'question': 2.544813856317907, 'response': 6.277546368440162, 'category': 0.1802135580026576}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:03:05,995] Trial 19 finished with value: 0.019639361789620856 and parameters: {'intent': 0.200484578873926, 'question': 2.2574678669279464, 'response': 7.001745588649078, 'category': 0.40549996892142914}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:03:06,427] Trial 21 finished with value: 0.019322723908216134 and parameters: {'intent': 9.436577993691845, 'question': 2.7512488023073383, 'response': 6.683814725242862, 'category': 0.42680013939241856}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:03:07,163] Trial 20 finished with value: 0.01929722839049263 and parameters: {'intent': 9.515102385498455, 'question': 2.916817575757261, 'response': 6.646409637977609, 'category': 0.03977109520789934}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:03:07,394] Trial 23 finished with value: 0.0197269512295419 and parameters: {'intent': 0.045086375447921156, 'question': 2.42830869142004, 'response': 6.957048238560193, 'category': 9.91606881447283}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:04:05,842] Trial 24 finished with value: 0.0201213093182005 and parameters: {'intent': 7.913908067901231, 'question': 2.6441129619456385, 'response': 6.944890956646314, 'category': 0.05323685699645608}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:04:07,108] Trial 27 finished with value: 0.015626696274364665 and parameters: {'intent': 0.7558934165051134, 'question': 1.7144133909946015, 'response': 1.6320315932637446, 'category': 9.809990512761857}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:04:07,816] Trial 26 finished with value: 0.0152220577350111 and parameters: {'intent': 0.6554887237824163, 'question': 2.0463432385053446, 'response': 1.379032795484834, 'category': 9.81307768478815}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:04:08,105] Trial 25 finished with value: 0.014966280121720533 and parameters: {'intent': 0.23360226172896859, 'question': 2.6231344131530756, 'response': 1.5329752909717866, 'category': 8.873678447962932}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:04:09,449] Trial 28 finished with value: 0.015654247882227156 and parameters: {'intent': 4.456360237244374, 'question': 1.8419506898247475, 'response': 1.5460341750871558, 'category': 2.076431089947992}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:04:09,814] Trial 29 finished with value: 0.01562505140225347 and parameters: {'intent': 4.579255762018283, 'question': 1.5345329902247835, 'response': 1.3693850806388443, 'category': 1.9604909032801197}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:04:10,992] Trial 31 finished with value: 0.016130849576445425 and parameters: {'intent': 4.408438949090953, 'question': 1.2274804788822662, 'response': 1.2798276331719292, 'category': 2.0792858920682282}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:04:11,568] Trial 30 finished with value: 0.015574882802862074 and parameters: {'intent': 4.3242881631867895, 'question': 1.703318250747283, 'response': 1.6324969576097856, 'category': 1.6845265007121784}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:05:11,982] Trial 34 finished with value: 0.020615182169586306 and parameters: {'intent': 4.477034759461606, 'question': 0.964681005041316, 'response': 4.2178269201856535, 'category': 1.8665860732845112}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:05:12,481] Trial 32 finished with value: 0.015574882802862074 and parameters: {'intent': 4.333803053985685, 'question': 1.755449103139906, 'response': 1.7034885548810053, 'category': 1.8395840611502807}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:05:14,707] Trial 35 finished with value: 0.017342709104367127 and parameters: {'intent': 4.151136149811369, 'question': 0.12672273587723148, 'response': 8.2742989451275, 'category': 1.8054689391584402}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:05:14,918] Trial 33 finished with value: 0.0171510815034131 and parameters: {'intent': 4.273263837126927, 'question': 0.0790679882858597, 'response': 4.139331619617443, 'category': 1.7607861005044105}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:05:15,626] Trial 36 finished with value: 0.01949091208158565 and parameters: {'intent': 6.605572253920085, 'question': 0.45672548532747087, 'response': 8.16519010094377, 'category': 1.4881372275723663}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:05:16,002] Trial 37 finished with value: 0.017335307179866758 and parameters: {'intent': 6.665499272073495, 'question': 0.1871120097993224, 'response': 8.274493039405343, 'category': 5.717490145777871}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:05:17,108] Trial 39 finished with value: 0.01722016613208322 and parameters: {'intent': 6.472844928060705, 'question': 0.1837013808436042, 'response': 8.299869737033871, 'category': 6.737257885543495}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:05:18,092] Trial 38 finished with value: 0.017308166790032064 and parameters: {'intent': 6.636762394925293, 'question': 0.13011134252292278, 'response': 8.453202662288527, 'category': 6.477071626815418}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:06:15,612] Trial 40 finished with value: 0.017076239822353803 and parameters: {'intent': 6.678462586890559, 'question': 0.04409379109710976, 'response': 8.529462414791011, 'category': 2.9085320664100385}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:06:16,550] Trial 41 finished with value: 0.017300764865531698 and parameters: {'intent': 6.588568552564388, 'question': 0.21400503798208426, 'response': 8.633506978793669, 'category': 2.7760917027482073}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:06:17,419] Trial 43 finished with value: 0.020094580146393617 and parameters: {'intent': 3.2696079315302757, 'question': 0.8104750606337731, 'response': 8.851631153660625, 'category': 2.7104299956678064}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:06:18,422] Trial 42 finished with value: 0.01765605724154946 and parameters: {'intent': 3.238152768833986, 'question': 0.1685911194344305, 'response': 4.1973242075349795, 'category': 2.9381862509082675}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:06:19,036] Trial 44 finished with value: 0.015378320585574468 and parameters: {'intent': 5.135640834530536, 'question': 3.358048615104381, 'response': 2.6813358288063247, 'category': 3.168072382237211}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:06:20,056] Trial 45 finished with value: 0.015523480549387281 and parameters: {'intent': 3.2967791774258384, 'question': 3.418552158721833, 'response': 2.56838851642967, 'category': 3.257714484903243}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:06:21,207] Trial 47 finished with value: 0.01401225429722839 and parameters: {'intent': 5.198932638576311, 'question': 6.020179237001843, 'response': 2.634759622924251, 'category': 3.502597176427103}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:06:21,622] Trial 46 finished with value: 0.019791923677934035 and parameters: {'intent': 5.3691118035930705, 'question': 3.5258806448818727, 'response': 9.028771370657966, 'category': 2.9669760362325124}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:06:34,515] Trial 48 finished with value: 0.020094580146393617 and parameters: {'intent': 5.14774264341292, 'question': 0.8689332383151714, 'response': 9.621838222271684, 'category': 3.5184482445889484}. Best is trial 3 with value: 0.020734846615675623.\n",
      "[I 2025-08-23 17:06:35,296] Trial 49 finished with value: 0.020166132083230526 and parameters: {'intent': 5.206042137175739, 'question': 1.0248866608805287, 'response': 9.89680242891725, 'category': 3.638829816202354}. Best is trial 3 with value: 0.020734846615675623.\n",
      "Best params: {'intent': 4.709344164326785, 'question': 0.9312117423908761, 'response': 5.71511647366386, 'category': 9.689631225548114}\n",
      "Best MRR: 0.020734846615675623\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest float values in the given ranges\n",
    "    boost_params = {\n",
    "        k: trial.suggest_float(k, low, high)\n",
    "        for k, (low, high) in param_ranges.items()\n",
    "    }\n",
    "\n",
    "    def search_function(q):\n",
    "        return minsearch_search(q, boost_params)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    results = evaluate(gt_val, search_function, disable=True)\n",
    "    return results['mrr']\n",
    "\n",
    "# Run optimization\n",
    "study = optuna.create_study(direction=\"maximize\")  # maximize MRR\n",
    "study.optimize(objective, n_trials=50, gc_after_trial=True, show_progress_bar=True, n_jobs=-1)\n",
    "\n",
    "# Best params\n",
    "print(\"Best params:\", study.best_params)\n",
    "print(\"Best MRR:\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d3759701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_improved(query, best_params):\n",
    "    boost = {\n",
    "       'intent': best_params[\"intent\"],\n",
    "        'question': best_params[\"question\"],\n",
    "        'response': best_params[\"response\"],\n",
    "        'category': best_params[\"category\"],\n",
    "    }\n",
    "\n",
    "    results = index.search(\n",
    "        query=query['question'],  # string directly or export\n",
    "        filter_dict={'category': query[\"category\"]},\n",
    "        boost_dict=boost,\n",
    "        num_results=10\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1ea5f794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af68b3da295a4e348e67cc5623f186fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1930 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.06217616580310881, 'mrr': 0.02112385886997287}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: minsearch_improved(q, best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9319b465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent': 1.1713429320851798,\n",
       " 'question': 2.204605368678285,\n",
       " 'response': 7.9458297171057595,\n",
       " 'category': 3.3253614921965546}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "54864e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent': 4.709344164326785,\n",
       " 'question': 0.9312117423908761,\n",
       " 'response': 5.71511647366386,\n",
       " 'category': 9.689631225548114}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "13221a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f93ce488d6b04df0988b6ae8b4a98a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1930 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.06424870466321243, 'mrr': 0.021246813060284583}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, lambda q: minsearch_improved(q, study.best_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de669d5-f9a4-4da0-b533-2781204ece3b",
   "metadata": {},
   "source": [
    "# RAG evaluation/monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c57fbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'intent': 4.709344164326785,\n",
    " 'question': 0.9312117423908761,\n",
    " 'response': 5.71511647366386,\n",
    " 'category': 9.689631225548114}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "96687ff0-3348-4743-a56a-786127c84fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, best_params):\n",
    "    boost = {\n",
    "       'intent': best_params[\"intent\"],\n",
    "        'question': best_params[\"question\"],\n",
    "        'response': best_params[\"response\"],\n",
    "        'category': best_params[\"category\"],\n",
    "    }\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'category': 'CONTENT'},  # Example filter on category field\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfe9b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()\n",
    "\n",
    "import os\n",
    "# os.environ[\"HF_TOKEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eef0c9-3e59-4b02-9f49-57f7ae78e84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))  # Initialize the OpenAI client\n",
    "\n",
    "# Connect to local Ollama instead of OpenAI cloud\n",
    "# client = OpenAI(\n",
    "#     # https://huggingface.co/openai/gpt-oss-120b\n",
    "#     # https://ollama.com/library/gpt-oss\n",
    "#     # ollama pull gpt-oss:20b\n",
    "#     # ollama run gpt-oss:120b\n",
    "#     # curl https://<your-forwarded-url>.app.github.dev/v1/models\n",
    "#     base_url=\"http://localhost:11434/v1\",  # Ollama API endpoint\n",
    "#     # base_url=\"https://glowing-carnival-qgwprp5pjjj255q-11434.app.github.dev/v1\",  # Ollama API endpoint\n",
    "#     api_key=\"ollama\"  # dummy key (ignored by Ollama)\n",
    "# )\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://router.huggingface.co/v1\",\n",
    "    api_key=os.environ[\"HF_TOKEN\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2450e48b-b4e3-4555-9e01-5674c3ff0404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "    You are a customer support assistant for the Media domain.\n",
    "    Answer the QUESTION using only the information from CONTEXT.\n",
    "\n",
    "    Rules:\n",
    "    - Only use facts from CONTEXT.\n",
    "    - Keep your answer clear, factual and concise.\n",
    "    - Do not hallucinate or add outside knowledge.\n",
    "    - Do not invent information not found in CONTEXT.\n",
    "    - If CONTEXT doesn’t contain the answer, respond: \"I don’t have that information.\"\n",
    "\n",
    "    QUESTION: {instruction}\n",
    "\n",
    "    CONTEXT:\n",
    "    {context}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    for doc in search_results:\n",
    "        context += (\n",
    "            f\"intent: {doc['intent']}\\n\"\n",
    "            f\"question: {doc['question']}\\n\"\n",
    "            f\"answer: {doc['response']}\\n\\n\"\n",
    "        )\n",
    "\n",
    "    # Add to template instruction and context\n",
    "    prompt = prompt_template.format(instruction=query, context=context).strip()\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        # model='gpt-4o-mini',  # OpenAI\n",
    "        # model=\"gpt-oss:20b\",   # Ollama \"llama3\" or any model available in your Ollama\n",
    "        model=\"openai/gpt-oss-120b:fireworks-ai\",  # huggingface\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        # temperature=0.0\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "def rag(query):\n",
    "    search_results = search(query, best_params)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c77a0a9e-3955-405f-8bff-66214f79e6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To report a copyright violation, please follow these steps:\n",
      "\n",
      "1. Visit **{{WEBSITE_URL}}**.  \n",
      "2. Go to the **{{COPYRIGHT_SECTION}}** section.  \n",
      "3. Select the **{{REPORT_COPYRIGHT_INFRINGEMENT_OPTION}}** option.  \n",
      "4. Complete the required fields with details about the infringement.  \n",
      "5. Submit the form for review.\n"
     ]
    }
   ],
   "source": [
    "question = 'I need assistance to the Media domain for copyright.'\n",
    "answer = rag(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8f6c2948",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2_template = \"\"\"\n",
    "You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n",
    "Your task is to judge the **relevance** of the generated answer to the given question.\n",
    "\n",
    "Guidelines:\n",
    "- Focus and analyze only on relevance the content and context of the generated answer in relation to the question, not style, grammar, or tone.\n",
    "- Use exactly one of the following labels:\n",
    "  - \"NON_RELEVANT\": The answer does not address the question.\n",
    "  - \"PARTLY_RELEVANT\": The answer addresses the question partially or contains both correct and irrelevant parts.\n",
    "  - \"RELEVANT\": The answer fully and directly addresses the question.\n",
    "- Keep the explanation brief (1-2 sentences).\n",
    "- Output valid parsable JSON without using code blocks only, no extra text.\n",
    "\n",
    "Evaluation Data:\n",
    "\n",
    "Question: {question}\n",
    "Generated Answer: {answer_llm}\n",
    "\n",
    "Output format:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bb3a0f2a-a232-4864-bf43-c93578667914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1930"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b2be59fd-2d38-4aeb-a335-025dc1cab029",
   "metadata": {},
   "outputs": [],
   "source": [
    "record = ground_truth[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c49d42c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I need assistance to the Media domain for copyright.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "808d4617",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_llm = answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "311e3d42-30a4-4fe7-906c-c3806442bc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n",
      "Your task is to judge the **relevance** of the generated answer to the given question.\n",
      "\n",
      "Guidelines:\n",
      "- Focus and analyze only on relevance the content and context of the generated answer in relation to the question, not style, grammar, or tone.\n",
      "- Use exactly one of the following labels:\n",
      "  - \"NON_RELEVANT\": The answer does not address the question.\n",
      "  - \"PARTLY_RELEVANT\": The answer addresses the question partially or contains both correct and irrelevant parts.\n",
      "  - \"RELEVANT\": The answer fully and directly addresses the question.\n",
      "- Keep the explanation brief (1-2 sentences).\n",
      "- Output valid parsable JSON without using code blocks only, no extra text.\n",
      "\n",
      "Evaluation Data:\n",
      "\n",
      "Question: I need assistance to the Media domain for copyright.\n",
      "Generated Answer: To report a copyright violation, please follow these steps:\n",
      "\n",
      "1. Visit **{{WEBSITE_URL}}**.  \n",
      "2. Go to the **{{COPYRIGHT_SECTION}}** section.  \n",
      "3. Select the **{{REPORT_COPYRIGHT_INFRINGEMENT_OPTION}}** option.  \n",
      "4. Complete the required fields with details about the infringement.  \n",
      "5. Submit the form for review.\n",
      "\n",
      "Output format:\n",
      "\n",
      "{\n",
      "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
      "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt2_template.format(question=question, answer_llm=answer_llm)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c081e711-4e5c-4cd4-bc8d-79a29c1f1d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6da1bf76-7670-4723-847d-15aad4a5d4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_question.sample(n=200, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "98a38031-1e2b-4134-bc88-6d9e857771f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = df_sample.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "634f85f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "13b87bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.034609954165976"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.uniform(10, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a66cdc62-803c-4c79-a687-581788fe1d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "696c7a54488f4a428d08396d92bef79a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "APIStatusError",
     "evalue": "Error code: 402 - {'error': 'You have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits.'}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAPIStatusError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      6\u001b[39m answer_llm = rag(question) \n\u001b[32m      7\u001b[39m prompt = prompt2_template.format(\n\u001b[32m      8\u001b[39m     question=question,\n\u001b[32m      9\u001b[39m     answer_llm=answer_llm\n\u001b[32m     10\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m evaluation_response = llm(prompt).choices[\u001b[32m0\u001b[39m].message.content\n\u001b[32m     13\u001b[39m evaluation = json.loads(evaluation_response)\n\u001b[32m     15\u001b[39m evaluations.append((record, answer_llm, evaluation))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mllm\u001b[39m\u001b[34m(prompt)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mllm\u001b[39m(prompt):\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     response = client.chat.completions.create(\n\u001b[32m     34\u001b[39m         \u001b[38;5;66;03m# model='gpt-4o-mini',  # OpenAI\u001b[39;00m\n\u001b[32m     35\u001b[39m         \u001b[38;5;66;03m# model=\"gpt-oss:20b\",   # Ollama \"llama3\" or any model available in your Ollama\u001b[39;00m\n\u001b[32m     36\u001b[39m         model=\u001b[33m\"\u001b[39m\u001b[33mopenai/gpt-oss-120b:fireworks-ai\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[38;5;66;03m# huggingface\u001b[39;00m\n\u001b[32m     37\u001b[39m         messages=[{\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: prompt}],\n\u001b[32m     38\u001b[39m         \u001b[38;5;66;03m# temperature=0.0\u001b[39;00m\n\u001b[32m     39\u001b[39m     )\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\0apps\\miniconda3\\envs\\py312\\Lib\\site-packages\\openai\\_utils\\_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\0apps\\miniconda3\\envs\\py312\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1147\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1101\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1103\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1144\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m   1145\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1146\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m   1148\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m/chat/completions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1149\u001b[39m         body=maybe_transform(\n\u001b[32m   1150\u001b[39m             {\n\u001b[32m   1151\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages,\n\u001b[32m   1152\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m   1153\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33maudio\u001b[39m\u001b[33m\"\u001b[39m: audio,\n\u001b[32m   1154\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n\u001b[32m   1155\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfunction_call\u001b[39m\u001b[33m\"\u001b[39m: function_call,\n\u001b[32m   1156\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfunctions\u001b[39m\u001b[33m\"\u001b[39m: functions,\n\u001b[32m   1157\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mlogit_bias\u001b[39m\u001b[33m\"\u001b[39m: logit_bias,\n\u001b[32m   1158\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mlogprobs\u001b[39m\u001b[33m\"\u001b[39m: logprobs,\n\u001b[32m   1159\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_completion_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_completion_tokens,\n\u001b[32m   1160\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_tokens,\n\u001b[32m   1161\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m   1162\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmodalities\u001b[39m\u001b[33m\"\u001b[39m: modalities,\n\u001b[32m   1163\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m: n,\n\u001b[32m   1164\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: parallel_tool_calls,\n\u001b[32m   1165\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mprediction\u001b[39m\u001b[33m\"\u001b[39m: prediction,\n\u001b[32m   1166\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mpresence_penalty\u001b[39m\u001b[33m\"\u001b[39m: presence_penalty,\n\u001b[32m   1167\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mprompt_cache_key\u001b[39m\u001b[33m\"\u001b[39m: prompt_cache_key,\n\u001b[32m   1168\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mreasoning_effort\u001b[39m\u001b[33m\"\u001b[39m: reasoning_effort,\n\u001b[32m   1169\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m: response_format,\n\u001b[32m   1170\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33msafety_identifier\u001b[39m\u001b[33m\"\u001b[39m: safety_identifier,\n\u001b[32m   1171\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m: seed,\n\u001b[32m   1172\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mservice_tier\u001b[39m\u001b[33m\"\u001b[39m: service_tier,\n\u001b[32m   1173\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: stop,\n\u001b[32m   1174\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m\"\u001b[39m: store,\n\u001b[32m   1175\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m   1176\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstream_options\u001b[39m\u001b[33m\"\u001b[39m: stream_options,\n\u001b[32m   1177\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m   1178\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m   1179\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m   1180\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_logprobs\u001b[39m\u001b[33m\"\u001b[39m: top_logprobs,\n\u001b[32m   1181\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m   1182\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n\u001b[32m   1183\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mverbosity\u001b[39m\u001b[33m\"\u001b[39m: verbosity,\n\u001b[32m   1184\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mweb_search_options\u001b[39m\u001b[33m\"\u001b[39m: web_search_options,\n\u001b[32m   1185\u001b[39m             },\n\u001b[32m   1186\u001b[39m             completion_create_params.CompletionCreateParamsStreaming\n\u001b[32m   1187\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[32m   1188\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m completion_create_params.CompletionCreateParamsNonStreaming,\n\u001b[32m   1189\u001b[39m         ),\n\u001b[32m   1190\u001b[39m         options=make_request_options(\n\u001b[32m   1191\u001b[39m             extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m   1192\u001b[39m         ),\n\u001b[32m   1193\u001b[39m         cast_to=ChatCompletion,\n\u001b[32m   1194\u001b[39m         stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1195\u001b[39m         stream_cls=Stream[ChatCompletionChunk],\n\u001b[32m   1196\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\0apps\\miniconda3\\envs\\py312\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\0apps\\miniconda3\\envs\\py312\\Lib\\site-packages\\openai\\_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAPIStatusError\u001b[39m: Error code: 402 - {'error': 'You have exceeded your monthly included credits for Inference Providers. Subscribe to PRO to get 20x more monthly included credits.'}"
     ]
    }
   ],
   "source": [
    "evaluations = []\n",
    "\n",
    "for record in tqdm(sample):\n",
    "    time.sleep(np.random.uniform(20, 30))\n",
    "    question = record['question']\n",
    "    answer_llm = rag(question) \n",
    "    prompt = prompt2_template.format(\n",
    "        question=question,\n",
    "        answer_llm=answer_llm\n",
    "    )\n",
    "\n",
    "    evaluation_response = llm(prompt).choices[0].message.content\n",
    "    evaluation = json.loads(evaluation_response)\n",
    "\n",
    "    evaluations.append((record, answer_llm, evaluation))\n",
    "    with open('evaluation.json', 'w') as json_file:\n",
    "        json.dump(evaluations, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef718d15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cf61170e-bfde-4889-8cd3-98fbfcc89918",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = pd.DataFrame(evaluations, columns=['record', 'answer', 'evaluation'])\n",
    "\n",
    "df_eval['id'] = df_eval.record.apply(lambda d: d['id'])\n",
    "df_eval['question'] = df_eval.record.apply(lambda d: d['question'])\n",
    "\n",
    "df_eval['relevance'] = df_eval.evaluation.apply(lambda d: d['Relevance'])\n",
    "df_eval['explanation'] = df_eval.evaluation.apply(lambda d: d['Explanation'])\n",
    "\n",
    "del df_eval['record']\n",
    "del df_eval['evaluation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a54e7c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relevance\n",
       "RELEVANT           0.826087\n",
       "NON_RELEVANT       0.123188\n",
       "PARTLY_RELEVANT    0.050725\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval.relevance.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9492ff9c-d633-4d02-a573-217e3978ccbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>relevance</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I don’t have that information.</td>\n",
       "      <td>0d94a91c</td>\n",
       "      <td>Could I contact the community managers directl...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The answer states lack of information and does...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>I don’t have that information.</td>\n",
       "      <td>7de19bdb</td>\n",
       "      <td>What steps should I take to submit a complaint...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The answer does not provide any steps or infor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>I don’t have that information.</td>\n",
       "      <td>c1eb2c2b</td>\n",
       "      <td>What are the steps and options available for r...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The answer does not provide any steps or optio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>I don’t have that information.</td>\n",
       "      <td>f634cfdf</td>\n",
       "      <td>Could you inform me about any possible procedu...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The answer states a lack of information and do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>I don’t have that information.</td>\n",
       "      <td>dc9097b0</td>\n",
       "      <td>Can someone assist me in understanding the pro...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The response states a lack of information and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>I don’t have that information.</td>\n",
       "      <td>3f3d1f47</td>\n",
       "      <td>If an advertisement seems misleading and thus ...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The answer does not provide any information ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>I don’t have that information.</td>\n",
       "      <td>fba65cab</td>\n",
       "      <td>I need directions, but I am currently not near...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The answer does not provide any directions or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>I don’t have that information.</td>\n",
       "      <td>5b52f0ec</td>\n",
       "      <td>'Deny unauthorised content' or 'flag policy br...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The answer provides no clarification or instru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>I don’t have that information.</td>\n",
       "      <td>ed546a3b</td>\n",
       "      <td>As someone bilingual who uses both English and...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The answer states lack of information and does...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>I don’t have that information.</td>\n",
       "      <td>521e7904</td>\n",
       "      <td>If we're discussing rights enforcement on your...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The answer states a lack of information and do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>I don’t have that information.</td>\n",
       "      <td>941580d3</td>\n",
       "      <td>Considering I find some content potentially bi...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The answer states a lack of information and do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>I don’t have that information.</td>\n",
       "      <td>801a2f21</td>\n",
       "      <td>Can you guide me through contacting customer s...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The response fails to provide any guidance on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>I don’t have that information.</td>\n",
       "      <td>044e907c</td>\n",
       "      <td>Is there anyone available at these hours that ...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The answer provides no information about the a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>I don’t have that information.</td>\n",
       "      <td>66ade00c</td>\n",
       "      <td>After I claim what seems like copyright blunde...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The answer states lack of information and does...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>I don’t have that information.</td>\n",
       "      <td>8f35ee5f</td>\n",
       "      <td>In case a creator’sexpression appears to viola...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The answer provides no information about the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>I don’t have that information.</td>\n",
       "      <td>8272a09d</td>\n",
       "      <td>If there's something not up to policy on Media...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The answer states lack of information and does...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>I don’t have that information.</td>\n",
       "      <td>889c481c</td>\n",
       "      <td>Can you explain where on your English-language...</td>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The answer does not provide any location or gu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             answer        id  \\\n",
       "13   I don’t have that information.  0d94a91c   \n",
       "33   I don’t have that information.  7de19bdb   \n",
       "39   I don’t have that information.  c1eb2c2b   \n",
       "40   I don’t have that information.  f634cfdf   \n",
       "56   I don’t have that information.  dc9097b0   \n",
       "57   I don’t have that information.  3f3d1f47   \n",
       "63   I don’t have that information.  fba65cab   \n",
       "67   I don’t have that information.  5b52f0ec   \n",
       "71   I don’t have that information.  ed546a3b   \n",
       "78   I don’t have that information.  521e7904   \n",
       "83   I don’t have that information.  941580d3   \n",
       "108  I don’t have that information.  801a2f21   \n",
       "111  I don’t have that information.  044e907c   \n",
       "112  I don’t have that information.  66ade00c   \n",
       "121  I don’t have that information.  8f35ee5f   \n",
       "133  I don’t have that information.  8272a09d   \n",
       "137  I don’t have that information.  889c481c   \n",
       "\n",
       "                                              question     relevance  \\\n",
       "13   Could I contact the community managers directl...  NON_RELEVANT   \n",
       "33   What steps should I take to submit a complaint...  NON_RELEVANT   \n",
       "39   What are the steps and options available for r...  NON_RELEVANT   \n",
       "40   Could you inform me about any possible procedu...  NON_RELEVANT   \n",
       "56   Can someone assist me in understanding the pro...  NON_RELEVANT   \n",
       "57   If an advertisement seems misleading and thus ...  NON_RELEVANT   \n",
       "63   I need directions, but I am currently not near...  NON_RELEVANT   \n",
       "67   'Deny unauthorised content' or 'flag policy br...  NON_RELEVANT   \n",
       "71   As someone bilingual who uses both English and...  NON_RELEVANT   \n",
       "78   If we're discussing rights enforcement on your...  NON_RELEVANT   \n",
       "83   Considering I find some content potentially bi...  NON_RELEVANT   \n",
       "108  Can you guide me through contacting customer s...  NON_RELEVANT   \n",
       "111  Is there anyone available at these hours that ...  NON_RELEVANT   \n",
       "112  After I claim what seems like copyright blunde...  NON_RELEVANT   \n",
       "121  In case a creator’sexpression appears to viola...  NON_RELEVANT   \n",
       "133  If there's something not up to policy on Media...  NON_RELEVANT   \n",
       "137  Can you explain where on your English-language...  NON_RELEVANT   \n",
       "\n",
       "                                           explanation  \n",
       "13   The answer states lack of information and does...  \n",
       "33   The answer does not provide any steps or infor...  \n",
       "39   The answer does not provide any steps or optio...  \n",
       "40   The answer states a lack of information and do...  \n",
       "56   The response states a lack of information and ...  \n",
       "57   The answer does not provide any information ab...  \n",
       "63   The answer does not provide any directions or ...  \n",
       "67   The answer provides no clarification or instru...  \n",
       "71   The answer states lack of information and does...  \n",
       "78   The answer states a lack of information and do...  \n",
       "83   The answer states a lack of information and do...  \n",
       "108  The response fails to provide any guidance on ...  \n",
       "111  The answer provides no information about the a...  \n",
       "112  The answer states lack of information and does...  \n",
       "121  The answer provides no information about the s...  \n",
       "133  The answer states lack of information and does...  \n",
       "137  The answer does not provide any location or gu...  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval[df_eval.relevance == 'NON_RELEVANT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e19c8fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>relevance</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>To report the disturbing article, follow these...</td>\n",
       "      <td>3c7c1979</td>\n",
       "      <td>I encountered a disturbing article on your web...</td>\n",
       "      <td>PARTLY_RELEVANT</td>\n",
       "      <td>The answer outlines the reporting steps, which...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>You should start by visiting the company’s off...</td>\n",
       "      <td>3e980aab</td>\n",
       "      <td>I want to alert you about someone posting my o...</td>\n",
       "      <td>PARTLY_RELEVANT</td>\n",
       "      <td>The answer suggests starting at the company's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>After you submit the accusation, your report i...</td>\n",
       "      <td>c3c92293</td>\n",
       "      <td>What actions are taken after I submit an accus...</td>\n",
       "      <td>PARTLY_RELEVANT</td>\n",
       "      <td>The answer mentions that the report is reviewe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>To submit a complaint about sexually explicit ...</td>\n",
       "      <td>d8906304</td>\n",
       "      <td>What steps should be taken to submit a complai...</td>\n",
       "      <td>PARTLY_RELEVANT</td>\n",
       "      <td>The answer outlines general steps for reportin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Yes. When you report a potential copyright inf...</td>\n",
       "      <td>521e7904</td>\n",
       "      <td>Is there specific information I need to provid...</td>\n",
       "      <td>PARTLY_RELEVANT</td>\n",
       "      <td>The answer acknowledges that specific details ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>To report a possible copyright infringement, f...</td>\n",
       "      <td>f5810df0</td>\n",
       "      <td>What steps do I need to follow after finding a...</td>\n",
       "      <td>PARTLY_RELEVANT</td>\n",
       "      <td>The answer offers generic reporting steps rela...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>You’ll need to fill out the official copyright...</td>\n",
       "      <td>caa8e588</td>\n",
       "      <td>What information do I have to provide in detai...</td>\n",
       "      <td>PARTLY_RELEVANT</td>\n",
       "      <td>The answer mentions that detailed information ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                answer        id  \\\n",
       "8    To report the disturbing article, follow these...  3c7c1979   \n",
       "16   You should start by visiting the company’s off...  3e980aab   \n",
       "50   After you submit the accusation, your report i...  c3c92293   \n",
       "55   To submit a complaint about sexually explicit ...  d8906304   \n",
       "80   Yes. When you report a potential copyright inf...  521e7904   \n",
       "125  To report a possible copyright infringement, f...  f5810df0   \n",
       "129  You’ll need to fill out the official copyright...  caa8e588   \n",
       "\n",
       "                                              question        relevance  \\\n",
       "8    I encountered a disturbing article on your web...  PARTLY_RELEVANT   \n",
       "16   I want to alert you about someone posting my o...  PARTLY_RELEVANT   \n",
       "50   What actions are taken after I submit an accus...  PARTLY_RELEVANT   \n",
       "55   What steps should be taken to submit a complai...  PARTLY_RELEVANT   \n",
       "80   Is there specific information I need to provid...  PARTLY_RELEVANT   \n",
       "125  What steps do I need to follow after finding a...  PARTLY_RELEVANT   \n",
       "129  What information do I have to provide in detai...  PARTLY_RELEVANT   \n",
       "\n",
       "                                           explanation  \n",
       "8    The answer outlines the reporting steps, which...  \n",
       "16   The answer suggests starting at the company's ...  \n",
       "50   The answer mentions that the report is reviewe...  \n",
       "55   The answer outlines general steps for reportin...  \n",
       "80   The answer acknowledges that specific details ...  \n",
       "125  The answer offers generic reporting steps rela...  \n",
       "129  The answer mentions that detailed information ...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval[df_eval.relevance == 'PARTLY_RELEVANT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3b1acbc2-9690-4d51-98a6-b81ee659ceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.to_csv('../Data/rag-eval-gpt-oss-120b.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade00f45-1aaf-4236-9452-cdd4bb47fd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_eval.to_csv('../data/rag-eval-gpt-4o.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4859cf7a-e4da-4b70-85f9-222a335571c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "816cb429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install vLLM with GPT-OSS support:\n",
    "# uv venv --python 3.12 --seed\n",
    "# source .venv/bin/activate\n",
    "# uv pip install --pre vllm==0.10.1+gptoss \\\n",
    "#     --extra-index-url https://wheels.vllm.ai/gpt-oss/ \\\n",
    "#     --extra-index-url https://download.pytorch.org/whl/nightly/cu128 \\\n",
    "#     --index-strategy unsafe-best-match\n",
    "\n",
    "# Launch the API server:\n",
    "# vllm serve openai/gpt-oss-20b\n",
    "# or\n",
    "# vllm serve openai/gpt-oss-120b\n",
    "\n",
    "# from openai import OpenAI\n",
    "# client = OpenAI(\n",
    "#     base_url=\"http://localhost:8000/v1\",\n",
    "#     api_key=\"EMPTY\"\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
